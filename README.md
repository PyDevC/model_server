# Model server

Inference various LLMs by while managing memory with onloading and offloading of models

## FEATURES
- Load any model via huggingface
- Load layers of model with hf_model.memory
- Several modelcards for basic inferencing
- Function name argument parser for easly cli
- Easily extensible

## Installation

```bash
pip install -r requirements.txt
```

## Usage

```bash
python3 src/maininference.py start
```
